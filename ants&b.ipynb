{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9sr9UK9CU-_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "O19NC--c1v1f"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "IMG_SIZE=224\n",
        "BATCH_SIZE=32\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "stFHrgvKCg6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen=ImageDataGenerator(rescale=1.225,validation_split=0.2)\n",
        "train_generator=train_datagen.flow_from_directory(\"/content/drive/MyDrive/antsvsbe/hymenoptera/train\",target_size=(IMG_SIZE,IMG_SIZE),\n",
        "                                                  batch_size=BATCH_SIZE,class_mode='binary',subset='training')\n",
        "val_generator=train_datagen.flow_from_directory(\"/content/drive/MyDrive/antsvsbe/hymenoptera/train\",target_size=(IMG_SIZE,IMG_SIZE),\n",
        "                                                  batch_size=BATCH_SIZE,class_mode='binary',subset='validation')\n",
        "test_datagen=ImageDataGenerator(rescale=1./225)\n",
        "test_generator=test_datagen.flow_from_directory(\"/content/drive/MyDrive/antsvsbe/hymenoptera/train\",target_size=(IMG_SIZE,IMG_SIZE),\n",
        "                                                  batch_size=BATCH_SIZE,class_mode='binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3By9qrz3I18",
        "outputId": "31e03e38-85eb-4275-98a6-a44a0508ea4d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 122 images belonging to 2 classes.\n",
            "Found 29 images belonging to 2 classes.\n",
            "Found 151 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DsyCRxbuEeQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=keras.Sequential([layers.Conv2D(32,(3,3),activation='relu',input_shape=(IMG_SIZE,IMG_SIZE,3)),\n",
        "layers.MaxPooling2D((2,2)),\n",
        "layers.Conv2D(32,(3,3),activation='relu'),\n",
        "layers.MaxPooling2D((2,2)),\n",
        "layers.Conv2D(64,(3,3),activation='relu'),\n",
        "layers.MaxPooling2D((2,2)),\n",
        "layers.Flatten(),\n",
        "layers.Dense(128,activation='relu'),\n",
        "layers.Dense(1,activation='sigmoid')])\n",
        "\n"
      ],
      "metadata": {
        "id": "F2ozL5x49Pa2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "6QmqFeIkEnIi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit(train_generator,validation_data=val_generator,epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4utr30jFX5_",
        "outputId": "d3ad4ed7-b6f0-4744-8b72-9038cae20af6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "4/4 [==============================] - 15s 3s/step - loss: 457.2454 - accuracy: 0.5328 - val_loss: 87.8192 - val_accuracy: 0.8276\n",
            "Epoch 2/5\n",
            "4/4 [==============================] - 12s 3s/step - loss: 61.5259 - accuracy: 0.8115 - val_loss: 13.9855 - val_accuracy: 0.8276\n",
            "Epoch 3/5\n",
            "4/4 [==============================] - 9s 2s/step - loss: 13.6514 - accuracy: 0.6393 - val_loss: 9.3380 - val_accuracy: 0.8276\n",
            "Epoch 4/5\n",
            "4/4 [==============================] - 11s 2s/step - loss: 7.0895 - accuracy: 0.8115 - val_loss: 1.7620 - val_accuracy: 0.7586\n",
            "Epoch 5/5\n",
            "4/4 [==============================] - 11s 3s/step - loss: 2.4670 - accuracy: 0.7049 - val_loss: 5.0612 - val_accuracy: 0.8276\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"Model.h5\",\"label.txt\")\n"
      ],
      "metadata": {
        "id": "mtqSwqUhlQol",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cda99d3a-5a39-4337-8371-9322bf769113"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "# Load the saved model\n",
        "model = load_model('/content/model12.h5')\n",
        "# Load and preprocess the test image\n",
        "test_image_path = '/content/drive/MyDrive/antsvsbe/hymenoptera/train/ants/1924473702_daa9aacdbe.jpg'\n",
        "img = image.load_img(test_image_path, target_size=(224, 224))\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "img_array /= 255.  # Normalize the pixel values\n",
        "# Make predictions\n",
        "prediction = model.predict(img_array)\n",
        "# Print the prediction\n",
        "if prediction < 0.5:\n",
        "    print(\"Prediction: ants (Probability:\", prediction[0][0], \")\")\n",
        "else:\n",
        "    print(\"Prediction: bees(Probability:\", prediction[0][0], \")\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyYKf1ahmGG0",
        "outputId": "552983af-fba2-4ddd-eb8f-c5f402863843"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x78f67e5ba290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 150ms/step\n",
            "Prediction: ants (Probability: 0.48885727 )\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "# Load the saved model\n",
        "model = load_model('/content/model12.h5')\n",
        "# Load and preprocess the test image\n",
        "test_image_path = '/content/drive/MyDrive/antsvsbe/hymenoptera/train/ants/1286984635_5119e80de1.jpg'\n",
        "img = image.load_img(test_image_path, target_size=(224, 224))\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "img_array /= 255.  # Normalize the pixel values\n",
        "# Make predictions\n",
        "prediction = model.predict(img_array)\n",
        "# Print the prediction\n",
        "if prediction < 0.5:\n",
        "    print(\"Prediction: ants (Probability:\", prediction[0][0], \")\")\n",
        "else:\n",
        "    print(\"Prediction: bees(Probability:\", prediction[0][0], \")\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKVxYPF5C1oM",
        "outputId": "f0ca158d-7c2d-41b8-8161-e797cb078a5b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 100ms/step\n",
            "Prediction: ants (Probability: 0.47870874 )\n"
          ]
        }
      ]
    }
  ]
}